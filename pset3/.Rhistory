x= "Log of Wage",
y= "residuals"
)
#Generate interaction terms
x <- to_matrix(nls80, c("exper","tenure","married","south","urban","black","educ"))
inter <- t(apply(x, 1, combn, 2, prod))
intervars <- c("exper_tenure", "exper_married", "exper_south", "exper_urban","exper_black", "exper_educ",  "tenure_married", "tenure_south", "tenure_urban","tenure_black", "tenure_educ", "married_south", "married_urban","married_black", "married_educ","south_urban", "south_black", "south_educ", "urban_black","urban_educ", "black_educ")
colnames(inter) <- intervars
#Generate squared vars
x <- to_matrix(nls80, c("exper","tenure","educ")) #only need non-dummy vars
x2 <- x^2
x2vars <- c("exper2","tenure2","educ2")
colnames(x2) <- x2vars
nls80 <- cbind(nls80, x2, inter)
results <- ols(
data = nls80, y_var = "e2",
X_vars = c("intercept","exper","tenure","married","south","urban","black","educ", x2vars, intervars), absorb = 0)
nR2 <- results[33,2]*nrow(x)
#p-value
pchisq(q = nR2, df = ncol(x2)+ncol(inter)+8-1, lower.tail=F)
# We reject the null of homoskedasticity: Houston, we have a problem
# Chunk 5: Q.2c Goldfeld-Quandt test for heteroskedastic errors.
#Choose our two subsamples
take = (nrow(nls80)-235)/2
top_tenure <- head(nls80[order(nls80$tenure, decreasing= T),], n = take)
bot_tenure <- head(nls80[order(nls80$tenure, decreasing= F),], n = take)
#Run OLS and record residuals for each
results <- ols(
data = top_tenure, y_var = "lwage",
X_vars = c("intercept","exper","tenure","married","south","urban","black","educ"), absorb = 0)
e_top <- e
results <- ols(
data = bot_tenure, y_var = "lwage",
X_vars = c("intercept","exper","tenure","married","south","urban","black","educ"), absorb = 0)
e_bot <- e
#Test statistic
F <- (t(e_top)%*%e_top)/(t(e_bot)%*%e_bot)
F<-F[1,1]
F
pf(q = F, df1 = ncol(top_tenure)-8, df2 =ncol(bot_tenure)-8)
#note: n1 − k = n2 − k
#We don't have an issue? Probably. P value is v low.
# Chunk 6: Q.2c Goldfeld-Quandt test for heteroskedastic errors.
#Choose our two subsamples
results <- ols(
data = nls80, y_var = "lwage",
X_vars = c("intercept","exper","tenure","married","south","urban","black","educ"), absorb = 0)
e2 <- e^2
#sigma squared hat
s2<-sum(e2)/dim(nls80)[1]
nls80$e2_normalized<-e2/s2
#create our z-vector
z<-c("intercept","exper","tenure","married","south","urban","black","educ")
results <- ols(
data = nls80 , y_var = "e2_normalized",
X_vars = z, absorb = 0)
nR2 <- results[9,2]*nrow(nls80)
pchisq(q = nR2, df = 7, lower.tail=F)
#0.001
results <- ols(
data = nls80, y_var = "lwage",
X_vars = c("intercept","exper","tenure","married","south","urban","black","educ"), absorb = 0)
e2 <- e^2
x <- to_matrix(nls80, c("intercept","exper","tenure","married","south","urban","black","educ"))
results <- ols(
data = nls80, y_var = "lwage",
X_vars = c("intercept","exper","tenure","married","south","urban","black","educ"), absorb = 0)
e2 <- e^2
x <- to_matrix(nls80, c("intercept","exper","tenure","married","south","urban","black","educ"))
xx_inv <- solve(t(x) %*% x)
sigma_hat <- lapply(x = 1:n, FUN = function(i) {
# Define x_i
x_i <- matrix(as.vector(x[i,]), nrow = 1)
# Return x_i' x_i e_i^2
return(t(x_i) %*% x_i * e[i]^2)
}) %>% Reduce(f = "+", x = .)
xx_inv %*% sigma_hat %*% xx_inv
xx_inv
sigma_hat <- lapply(x = 1:n, FUN = function(i) {
# Define x_i
x_i <- matrix(as.vector(x[i,]), nrow = 1)
# Return x_i' x_i e_i^2
return(t(x_i) %*% x_i * e[i]^2)
}) %>% Reduce(f = "+", x = .)
vcov_white <- function(data, y_var, X_vars, intercept = T) {
# Turn data into matrices
y <- to_matrix(data, y_var)
X <- to_matrix(data, X_vars)
# Add intercept
if (intercept == T) X <- cbind(1, X)
# Calculate n and k for degrees of freedom
n <- nrow(X)
k <- ncol(X)
# Estimate coefficients
b <- b_ols(y, X)
# Update names
if (intercept == T) rownames(b)[1] <- "Intercept"
# Calculate OLS residuals
e <- y - X %*% b
# Inverse of X'X
XX_inv <- solve(t(X) %*% X)
# For each row, calculate x_i' x_i e_i^2; then sum
sigma_hat <- lapply(X = 1:n, FUN = function(i) {
# Define x_i
x_i <- matrix(as.vector(X[i,]), nrow = 1)
# Return x_i' x_i e_i^2
return(t(x_i) %*% x_i * e[i]^2)
}) %>% Reduce(f = "+", x = .)
# Return the results
return(XX_inv %*% sigma_hat %*% XX_inv)
}
vcov_white(data = nls80,
y_var = "lwage",
X_vars = c("intercept","exper","tenure","married","south","urban","black","educ"))
vcov_white(data = nls80,
y_var = "lwage",
X_vars = c("exper","tenure","married","south","urban","black","educ"))
vcov_white <- function(data, y_var, X_vars, intercept = T) {
# Turn data into matrices
y <- to_matrix(data, y_var)
X <- to_matrix(data, X_vars)
# Add intercept
if (intercept == T) X <- cbind(1, X)
# Calculate n and k for degrees of freedom
n <- nrow(X)
k <- ncol(X)
# Estimate coefficients
b <- b_ols(y, X)
# Update names
if (intercept == T) rownames(b)[1] <- "Intercept"
# Calculate OLS residuals
e <- y - X %*% b
# Inverse of X'X
XX_inv <- solve(t(X) %*% X)
# For each row, calculate x_i' x_i e_i^2; then sum
sigma_hat <- lapply(X = 1:n, FUN = function(i) {
# Define x_i
x_i <- matrix(as.vector(X[i,]), nrow = 1)
# Return x_i' x_i e_i^2
return(t(x_i) %*% x_i * e[i]^2)
}) %>% Reduce(f = "+", x = .)
# Return the results
return(XX_inv %*% sigma_hat %*% XX_inv)
}
# Chunk 1: Data setup & defining functions
rm(list=ls())
options(scipen = 999)
# Packages
library(pacman)
library(ggpubr)
library(googledrive)
library(formattable)
p_load(dplyr, haven, readr, gdata, googledrive)
p_load(ggplot2, extrafont, Matrix, reshape, formattable)
p_load(dplyr, lfe, magrittr, ggplot2, viridis, sandwich)
# Directories
if (Sys.getenv("LOGNAME")=="AlexFavela") {
dir_data <- "~/Google Drive/ARE 212 Psets/Pset 3/"
}
if (Sys.getenv("LOGNAME")=="matthewtarduno") {
dir_data <- "~/Google Drive/ARE 212 Psets/Pset 3/"
# If this doesn't work, set your gdrive path
}
if (Sys.getenv("LOGNAME")=="") {
dir_data <- "C:/Users/sphan/Google Drive/ARE 212 Psets/Pset 3/"
}
## Theme
SAP_theme <- theme(
panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"),
plot.title = element_text(size = 16, face = "bold"), axis.text=element_text(size=14),
axis.title.x=element_text(size=14,face="bold", margin = margin(t = 30, r = 0, b = 0, l = 0)),
axis.title.y=element_text(size=14,face="bold", margin = margin(t = 0, r = 0, b = 0, l = 15)),
axis.text.x=element_text(size = 12)
)
##
# To MATRIX ############################################################################
# Function to convert tibble, data.frame, or tbl_df to matrix ----
to_matrix <- function(the_df, vars) {
# Create a matrix from variables in var
new_mat <- the_df %>%
# Select the columns given in 'vars'
select_(.dots = vars) %>%
# Convert to matrix
as.matrix()
# Return 'new_mat'
return(new_mat)
}
# Simple OLS ################################################################################
b_ols <- function(data, y_var, X_vars) {
# Create the y matrix
y <- to_matrix(the_df = data, vars = y_var)
# Create the X matrix
X <- to_matrix(the_df = data, vars = X_vars)
# Calculate beta hat
beta_hat <- solve(t(X) %*% X) %*% t(X) %*% y
# Return beta_hat
return(beta_hat)
}
# OLS + stats################################################################################
ols <- function(data, y_var, X_vars, absorb) {
# Turn data into matrices
y <- to_matrix(data, y_var)
X <- to_matrix(data, X_vars)
# Calculate n and k for degrees of freedom
n <- nrow(X)
k <- ncol(X)
# Estimate coefficients
b <- b_ols(data, y_var, X_vars)
# Calculate OLS residuals
e <- y - X %*% b
assign("e", e, .GlobalEnv)
# Calculate s^2
s2 <- (t(e) %*% e) / (n-k)
# Update s2 to numeric
s2 %<>% as.numeric()
# Inverse of X'X
XX_inv <- solve(t(X) %*% X)
# Standard error
se <- sqrt(s2 * diag(XX_inv))
t <- b / se
# Adjusted R-sq
y_hat <- y - e
SSM_demean <- sum((y_hat - mean(y)) * (y_hat - mean(y)))
SST_demean <- sum((y - mean(y)) * (y - mean(y)))
SSR <- sum(e * e)
R <- 1 - SSR/SST_demean
R <- formattable(R, digits = 3, format = "f")
R_adj <- 1 - ((1 - R) * (n-1)/(n-k-absorb))
R_adj <- formattable(R_adj, digits = 3, format = "f")
# Nice table (data.frame) of results
results <- data.frame(
# The rows have the coef. names
effect = rownames(b),
# Estimated coefficients
coef = formattable(as.vector(b), digits = 3, format = "f"),
# Standard errors
std_error = formattable(as.vector(se), digits = 3, format = "f"),
# T-stat for beta = 0
tstat0 = formattable(as.vector(t), digits = 3, format = "f")
)
rsq <- data.frame(
effect = c("R", "R_adj"),
coef = c(R,R_adj),
std_error = as.numeric(c("","")),
tstat0 = as.numeric(c("",""))
)
results<- rbind(results, rsq)
# Return the results
return(results)
}
# t stats################################################################################
t_stat <- function(data, y_var, X_vars, gamma) {
# Turn data into matrices
y <- to_matrix(data, y_var)
X <- to_matrix(data, X_vars)
# Add intercept if requested
# Calculate n and k for degrees of freedom
n <- nrow(X)
k <- ncol(X)
# Estimate coefficients
b <- b_ols(data, y_var, X_vars)
# Calculate OLS residuals
e <- y - X %*% b
# Calculate s^2
s2 <- (t(e) %*% e) / (n-k)
# Force s2 to numeric
s2 %<>% as.numeric()
# Inverse of X'X
XX_inv <- solve(t(X) %*% X)
# Standard error
se <- sqrt(s2 * diag(XX_inv))
# Vector of _t_ statistics
t_stats <- (b - gamma) / se
# Return the _t_ statistics
return(t_stats)
}
############################################################################################
# Chunk 2: Q.1 Read data into R and plot series.
nls80 <- read_csv(paste0(dir_data, "nls80.csv"))
#Sort data by wage
nls80 <- nls80[order(wage),]
#Scatterplot series to identify outliers
clist <- list("exper","tenure","married","south","urban","black","educ")
for (var in clist){
attach(nls80)
y_var = get(var)
gph = ggplot() +
geom_point(aes_(x = lwage, y = y_var),
col = "maroon",  alpha = .5, size = 2) +
ggtitle(paste0(var)) + ylab(var) + xlab("Log of Wafe") + SAP_theme
assign(paste0("gph_",var), gph)
}
detach(nls80)
variable_plot1<-ggarrange(
gph_exper, gph_tenure, gph_educ, ncol = 3, nrow = 1, align = "hv")
variable_plot2<-ggarrange(
gph_married, gph_south, gph_urban, gph_black, ncol = 2, nrow = 2, align = "hv")
remove(gph_exper, gph_tenure, gph_educ, gph_married, gph_south, gph_urban, gph_black)
#Data cleaning
nls80$intercept <- 1
# Chunk 3: Q.2a Estimate model
results <- ols(
data = nls80, y_var = "lwage",
X_vars = c("intercept","exper","tenure","married","south","urban", "black","educ"), absorb = 0)
# Chunk 4: Q.2b White test for heteroskedastic errors.
#Generate squared residuals
nls80$e <- e
nls80$e2 <- (e)^2
#Plot residuals^2 to get idea
scatter_e2<-ggplot(nls80, aes(y=e2, x=lwage)) +
geom_point(size=2, shape=19, color="darkblue", alpha=0.3)+
labs(
x= "Log of Wage",
y= "residuals"
)
#Generate interaction terms
x <- to_matrix(nls80, c("exper","tenure","married","south","urban","black","educ"))
inter <- t(apply(x, 1, combn, 2, prod))
intervars <- c("exper_tenure", "exper_married", "exper_south", "exper_urban","exper_black", "exper_educ",  "tenure_married", "tenure_south", "tenure_urban","tenure_black", "tenure_educ", "married_south", "married_urban","married_black", "married_educ","south_urban", "south_black", "south_educ", "urban_black","urban_educ", "black_educ")
colnames(inter) <- intervars
#Generate squared vars
x <- to_matrix(nls80, c("exper","tenure","educ")) #only need non-dummy vars
x2 <- x^2
x2vars <- c("exper2","tenure2","educ2")
colnames(x2) <- x2vars
nls80 <- cbind(nls80, x2, inter)
results <- ols(
data = nls80, y_var = "e2",
X_vars = c("intercept","exper","tenure","married","south","urban","black","educ", x2vars, intervars), absorb = 0)
nR2 <- results[33,2]*nrow(x)
#p-value
pchisq(q = nR2, df = ncol(x2)+ncol(inter)+8-1, lower.tail=F)
# We reject the null of homoskedasticity: Houston, we have a problem
# Chunk 5: Q.2c Goldfeld-Quandt test for heteroskedastic errors.
#Choose our two subsamples
take = (nrow(nls80)-235)/2
top_tenure <- head(nls80[order(nls80$tenure, decreasing= T),], n = take)
bot_tenure <- head(nls80[order(nls80$tenure, decreasing= F),], n = take)
#Run OLS and record residuals for each
results <- ols(
data = top_tenure, y_var = "lwage",
X_vars = c("intercept","exper","tenure","married","south","urban","black","educ"), absorb = 0)
e_top <- e
results <- ols(
data = bot_tenure, y_var = "lwage",
X_vars = c("intercept","exper","tenure","married","south","urban","black","educ"), absorb = 0)
e_bot <- e
#Test statistic
F <- (t(e_top)%*%e_top)/(t(e_bot)%*%e_bot)
F<-F[1,1]
F
pf(q = F, df1 = ncol(top_tenure)-8, df2 =ncol(bot_tenure)-8)
#note: n1 − k = n2 − k
#We don't have an issue? Probably. P value is v low.
# Chunk 6: Q.d Breusch  Pagan  Test test for heteroskedastic errors.
#Choose our two subsamples
results <- ols(
data = nls80, y_var = "lwage",
X_vars = c("intercept","exper","tenure","married","south","urban","black","educ"), absorb = 0)
e2 <- e^2
#sigma squared hat
s2<-sum(e2)/dim(nls80)[1]
nls80$e2_normalized<-e2/s2
#create our z-vector
z<-c("intercept","exper","tenure","married","south","urban","black","educ")
results <- ols(
data = nls80 , y_var = "e2_normalized",
X_vars = z, absorb = 0)
nR2 <- results[9,2]*nrow(nls80)
pchisq(q = nR2, df = 7, lower.tail=F)
#0.001
# Chunk 7: Q.e White standard errors
#Choose our two subsamples
results <- ols(
data = nls80, y_var = "lwage",
X_vars = c("intercept","exper","tenure","married","south","urban","black","educ"), absorb = 0)
e2 <- e^2
x <- to_matrix(nls80, c("intercept","exper","tenure","married","south","urban","black","educ"))
xx_inv <- solve(t(x) %*% x)
sigma_hat <- lapply(x = 1:n, FUN = function(i) {
# Define x_i
x_i <- matrix(as.vector(x[i,]), nrow = 1)
# Return x_i' x_i e_i^2
return(t(x_i) %*% x_i * e[i]^2)
}) %>% Reduce(f = "+", x = .)
xx_inv %*% sigma_hat %*% xx_inv
vcov_white <- function(data, y_var, X_vars, intercept = T) {
# Turn data into matrices
y <- to_matrix(data, y_var)
X <- to_matrix(data, X_vars)
# Add intercept
if (intercept == T) X <- cbind(1, X)
# Calculate n and k for degrees of freedom
n <- nrow(X)
k <- ncol(X)
# Estimate coefficients
b <- b_ols(y, X)
# Update names
if (intercept == T) rownames(b)[1] <- "Intercept"
# Calculate OLS residuals
e <- y - X %*% b
# Inverse of X'X
XX_inv <- solve(t(X) %*% X)
# For each row, calculate x_i' x_i e_i^2; then sum
sigma_hat <- lapply(X = 1:n, FUN = function(i) {
# Define x_i
x_i <- matrix(as.vector(X[i,]), nrow = 1)
# Return x_i' x_i e_i^2
return(t(x_i) %*% x_i * e[i]^2)
}) %>% Reduce(f = "+", x = .)
# Return the results
return(XX_inv %*% sigma_hat %*% XX_inv)
}
vcov_white(data = nls80,
y_var = "lwage",
X_vars = c("exper","tenure","married","south","urban","black","educ"))
#0.001
n <- nrow(x)
# Define x_i
x_i <- matrix(as.vector(x[i,]), nrow = 1)
# Return x_i' x_i e_i^2
return(t(x_i) %*% x_i * e[i]^2)
}) %>% Reduce(f = "+", x = .)
sigma_hat <- lapply(x = 1:n, FUN = function(i) {
# Define x_i
x_i <- matrix(as.vector(x[i,]), nrow = 1)
# Return x_i' x_i e_i^2
return(t(x_i) %*% x_i * e[i]^2)
}
sigma_hat <- lapply(x = 1:n, FUN = function(i) {
# Define x_i
x_i <- matrix(as.vector(x[i,]), nrow = 1)
# Return x_i' x_i e_i^2
return(t(x_i) %*% x_i * e[i]^2)
})
results <- ols(
data = nls80, y_var = "lwage",
X_vars = c("intercept","exper","tenure","married","south","urban","black","educ"), absorb = 0)
e2 <- e^2
x <- to_matrix(nls80, c("intercept","exper","tenure","married","south","urban","black","educ"))
xx_inv <- solve(t(x) %*% x)
n <- nrow(x)
# For each row, calculate x_i' x_i e_i^2; then sum
sigma_hat <- lapply(x = 1:n, FUN = function(i) {
# Define x_i
x_i <- matrix(as.vector(x[i,]), nrow = 1)
# Return x_i' x_i e_i^2
return(t(x_i) %*% x_i * e[i]^2)
}) %>% Reduce(f = "+", x = .)
n <- nrow(x)
Middle<-0
for (i in n) {
x_i <- matrix(as.vector(x[i,]), nrow = 1)
xxe<-t(x_i) %*% x_i * e[i]^2
Middle<-Middle+xxe
}
Middle
x <- to_matrix(nls80, c("intercept","exper","tenure","married","south","urban","black","educ"))
xx_inv <- solve(t(x) %*% x)
n <- nrow(x)
sigma_hat<-0
for (i in n) {
x_i <- matrix(as.vector(x[i,]), nrow = 1)
xxe<-t(x_i) %*% x_i * e[i]^2
sigma_hat<-sigma_hat+xxe
}
vcov_white <- xx_inv %*% sigma_hat %*% xx_inv
vcov_white
library(sandwich)
mod<-lm(lwage ~ exper + tenure + married + south + urban + black + educ, data=data)
mod<-lm(lwage ~ exper + tenure + married + south + urban + black + educ, data=nls80)
vcovHC(mod, type = "HC")
vcov_white
vcovHC(mod, type = "HC")
vcov_white-vcovHC(mod, type = "HC")
results <- ols(
data = nls80, y_var = "lwage",
X_vars = c("intercept","exper","tenure","married","south","urban","black","educ"), absorb = 0)
e2 <- e^2
x <- to_matrix(nls80, c("intercept","exper","tenure","married","south","urban","black","educ"))
xx_inv <- solve(t(x) %*% x)
n <- nrow(x)
sigma_hat<-0
for (i in n) {
x_i <- matrix(as.vector(x[i,]), nrow = 1)
xxe<-t(x_i) %*% x_i * e[i]^2
sigma_hat<-sigma_hat+xxe
}
vcov_white <- xx_inv %*% sigma_hat %*% xx_inv
vcov_white
mod<-lm(lwage ~ exper + tenure + married + south + urban + black + educ, data=nls80)
vcovHC(mod, type = "HC")
n <- nrow(x)
sigma_hat<-0
sigma_hat
for (i in n) {
x_i <- matrix(as.vector(x[i,]), nrow = 1)
xxe<-t(x_i) %*% x_i * e[i]^2
sigma_hat<-sigma_hat+xxe
}
sigma_hat
X <- to_matrix(nls80, c("intercept","exper","tenure","married","south","urban","black","educ"))
sigma_hat <- lapply(X = 1:n, FUN = function(i) {
# Define x_i
x_i <- matrix(as.vector(X[i,]), nrow = 1)
# Return x_i' x_i e_i^2
return(t(x_i) %*% x_i * e[i]^2)
}) %>% Reduce(f = "+", x = .)
sigma_hat
vcov_white <- xx_inv %*% sigma_hat %*% xx_inv
vcov_white-vcovHC(mod, type = "HC")
